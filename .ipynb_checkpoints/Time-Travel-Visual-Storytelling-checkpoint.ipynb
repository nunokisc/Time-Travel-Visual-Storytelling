{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Time-Travel-Visual-Storytelling</h1>\n",
    "\n",
    "<h4>Nelson Amaral, Nuno Cardoso, Tiago Santana </h4>\n",
    "<h3>Tomar, Janeiro 2019</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "* Python 3.7.x\n",
    "* spacy\n",
    "* json\n",
    "* requests\n",
    "* datetime\n",
    "* contamehistorias\n",
    "* relativedelta\n",
    "* flask\n",
    "* cors\n",
    "* selenium\n",
    "* OpenCV\n",
    "* numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar todas as dependencias necessarias (apenas a primeira vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download pt\n",
    "!pip install json\n",
    "!pip install requests\n",
    "!pip install git+https://github.com/LIAAD/TemporalSummarizationFramework.git\n",
    "!pip install python-dateutil\n",
    "!pip install flask\n",
    "!pip install flask-restful\n",
    "!pip install cors\n",
    "!pip install selenium\n",
    "!pip install numpy\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em baixo importamos dependencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import requests\n",
    "from contamehistorias.datasources.webarchive import ArquivoPT\n",
    "from datetime import datetime\n",
    "from contamehistorias import engine\n",
    "import os  \n",
    "from dateutil.relativedelta import relativedelta # $ pip install python-dateutil\n",
    "from flask import Flask, render_template, send_from_directory\n",
    "from flask_restful import Api, Resource, reqparse\n",
    "from flask_cors import CORS\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos a api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "cors = CORS(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionamos os dominios a ser consultados pelo contamehistorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['http://acervo.publico.pt/'\n",
    ",'http://inimigo.publico.pt/'\n",
    ",'http://publico.pt/'\n",
    ",'http://www.dn.pt/'\n",
    ",'http://dn.sapo.pt/'\n",
    ",'http://dnoticias.pt/'\n",
    ",'http://www.rtp.pt/'\n",
    ",'http://www.cmjornal.pt/'\n",
    ",'http://www.iol.pt/'\n",
    ",'http://www.tvi24.iol.pt/'\n",
    ",'http://noticias.sapo.pt/'\n",
    ",'http://www.sapo.pt/'\n",
    ",'http://expresso.sapo.pt/'\n",
    ",'http://sol.sapo.pt/'\n",
    ",'http://visao.sapo.pt/'\n",
    ",'http://exameinformatica.sapo.pt/'\n",
    ",'http://tek.sapo.pt/'\n",
    ",'http://www.jornaldenegocios.pt/'\n",
    ",'http://dinheirodigital.sapo.pt/'\n",
    ",'http://abola.pt/'\n",
    ",'http://www.abola.pt/'\n",
    ",'http://www.jn.pt/'\n",
    ",'http://jn.pt/'\n",
    ",'http://sicnoticias.sapo.pt/'\n",
    ",'http://www.lux.iol.pt/'\n",
    ",'http://maisfutebol.iol.pt/'\n",
    ",'http://lux.iol.pt/'\n",
    ",'http://www.ionline.pt/'\n",
    ",'http://ionline.sapo.pt/'\n",
    ",'http://news.google.pt/'\n",
    ",'http://www.dinheirovivo.pt/'\n",
    ",'http://www.aeiou.pt/'\n",
    ",'http://zap.aeiou.pt/'\n",
    ",'http://www.tsf.pt/'\n",
    ",'http://meiosepublicidade.pt/'\n",
    ",'http://www.sabado.pt/'\n",
    ",'http://www.omirante.pt/'\n",
    ",'http://www.jb.pt/'\n",
    ",'http://www.mdb.pt/'\n",
    ",'http://www.avante.pt/'\n",
    ",'http://www.oje.pt/'\n",
    ",'http://www.auniao.pt/'\n",
    ",'http://www.record.pt/'\n",
    ",'http://www.ojogo.pt/'\n",
    ",'http://zerozero.pt/'\n",
    ",'http://www.maisfutebol.iol.pt/'\n",
    ",'http://desporto.sapo.pt/'\n",
    ",'http://jornaleconomico.sapo.pt/'\n",
    ",'http://www.diarioleiria.pt/'\n",
    ",'http://www.regiaodeleiria.pt/'\n",
    ",'http://www.correiodominho.pt/'\n",
    ",'http://www.diariodominho.pt/'\n",
    ",'http://economico.sapo.pt/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos o limite temporal para consulta do contamehistorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'domains':domains, \n",
    "            'from':datetime(year=2010, month=1, day=1), \n",
    "            'to':datetime(year=2018, month=12, day=12) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo dos dados que usamos do contamehistorias com a query \"cristiano ronaldo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"cristiano ronaldo\" #query á escolha\n",
    "\n",
    "apt =  ArquivoPT()\n",
    "search_result = apt.getResult(query=query, **params)\n",
    "\n",
    "language = \"pt\"\n",
    "\n",
    "cont = engine.TemporalSummarizationEngine() #engine comtamehistorias\n",
    "intervals = cont.build_intervals(search_result, language) #criação dos intervalos temporais com headlines\n",
    "summ_result = cont.serialize(intervals) #serialize para ficar apenas com os dados bem formatados e com a informação mais relevante\n",
    "\n",
    "for period in summ_result[\"results\"]:\n",
    "   \n",
    "   print(\"--------------------------------\")\n",
    "   print(period[\"from\"],\"until\",period[\"to\"])\n",
    "   result_interval =   {   'from':str(period['from']), \n",
    "                                        'to':str(period['to'])\n",
    "                                    }\n",
    "   # selected keyphrases\n",
    "   keyphrases = period[\"keyphrases\"]\n",
    "   result_interval[\"headline\"] = []\n",
    "   for keyphrase in keyphrases:\n",
    "       print(keyphrase[\"kw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos o  Named Entity Recognition nos ultimos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm') #modelo portugues do spacy\n",
    "for keyphrase in keyphrases:\n",
    "    doc = nlp(keyphrase[\"kw\"])\n",
    "    for ent in doc.ents:\n",
    "       print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora adicionamos uma condição para apenas mostrar nomes de pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm') #modelo portugues do spacy\n",
    "for keyphrase in keyphrases:\n",
    "    doc = nlp(keyphrase[\"kw\"])\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PER\": #condição apenas para nomes de pessoas\n",
    "            print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste momento já temos tudo o que precisamos, temos os headlines e os nomes das pessoas isolados com as devidas posições no headline.\n",
    "Passamos agora para a pesquisa das pessoas na API de imagens do ArquivoPt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "for keyphrase in keyphrases:\n",
    "    doc = nlp(keyphrase[\"kw\"])\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PER\": #condição apenas para nomes de pessoas\n",
    "            #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "            datetime_object = datetime.strptime(str(keyphrase[\"date\"]), '%Y-%m-%d %H:%M:%S') #formatar a data para o formato pretendido\n",
    "            datetime_objectMoreOne = datetime_object + relativedelta(years=+1) # adicionar um ano à data para pesquisa na api de imagens\n",
    "            api_url_base = 'https://preprod.arquivo.pt/imagesearch/?' #url da API ArquivoPt\n",
    "            query1 = ent.text #nome para query\n",
    "            maxItems = 1 #maximo de resultados\n",
    "            prettyPrint = 'true' #formatação bonita de resultados\n",
    "            frm = datetime_object.strftime(\"%Y\") #data formatada\n",
    "            to = datetime_objectMoreOne.strftime(\"%Y\")#data formatada +1 ano\n",
    "            size = 'md' #tamanho das imagens \n",
    "            api_url = '{0}q={1}&maxItems={2}&prettyPrint={3}&to={4}&from={5}&size={6}'.format(api_url_base,query1,maxItems,prettyPrint,to,frm,size)\n",
    "            print()\n",
    "            print(api_url)\n",
    "            response = requests.get(api_url) #resposta api de imagens\n",
    "            imgApiResponse = response.json() #resposta em json api de imagens\n",
    "            print(imgApiResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados que nos recolhemos e usamos da API (em JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "newObject = []\n",
    "for keyphrase in keyphrases:\n",
    "    result_headline = {\n",
    "                        'headline':str(keyphrase[\"kw\"]),\n",
    "                        'date':str(keyphrase[\"date\"])\n",
    "                    }\n",
    "    result_headline[\"persons\"] = []\n",
    "    doc = nlp(keyphrase[\"kw\"])\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PER\": #condição apenas para nomes de pessoas\n",
    "            #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "            datetime_object = datetime.strptime(str(keyphrase[\"date\"]), '%Y-%m-%d %H:%M:%S') #formatar a data para o formato pretendido\n",
    "            datetime_objectMoreOne = datetime_object + relativedelta(years=+1) # adicionar um ano à data para pesquisa na api de imagens\n",
    "            api_url_base = 'https://preprod.arquivo.pt/imagesearch/?' #url da API ArquivoPt\n",
    "            query1 = ent.text #nome para query\n",
    "            maxItems = 1 #maximo de resultados\n",
    "            prettyPrint = 'true' #formatação bonita de resultados\n",
    "            frm = datetime_object.strftime(\"%Y%m%d%H%M%S\") #data formatada\n",
    "            to = datetime_objectMoreOne.strftime(\"%Y%m%d%H%M%S\")#data formatada +1 ano\n",
    "            size = 'md' #tamanho das imagens \n",
    "            type = 'png jpg jpeg'\n",
    "            api_url = '{0}q={1}&maxItems={2}&prettyPrint={3}&to={4}&from={5}&size={6}&type={7}'.format(api_url_base,query1,maxItems,prettyPrint,to,frm,size,type)\n",
    "            response = requests.get(api_url) #resposta api de imagens\n",
    "            imgApiResponse = response.json() #resposta em json api de imagens\n",
    "            if(len(imgApiResponse[\"responseItems\"]) > 0):\n",
    "                result_chunk =   {   'person':str(ent.text), \n",
    "                                    'start_char':str(ent.start_char),\n",
    "                                    'end_char':str(ent.end_char),\n",
    "                                    'date':str(keyphrase[\"date\"]),\n",
    "                                    'imgSrc':str(imgApiResponse[\"responseItems\"][0][\"imgLinkToArchive\"])\n",
    "                                }\n",
    "            else:\n",
    "                result_chunk =   {   'person':str(ent.text), \n",
    "                                    'start_char':str(ent.start_char),\n",
    "                                    'end_char':str(ent.end_char),\n",
    "                                    'date':str(keyphrase[\"date\"])\n",
    "                                }\n",
    "            result_headline[\"persons\"].append(result_chunk)\n",
    "    result_interval[\"headline\"].append(result_headline)\n",
    "    print(result_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados que nos recolhemos e usamos da API (Forma Visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "newObject = []\n",
    "for keyphrase in keyphrases:\n",
    "    result_headline = {\n",
    "                        'headline':str(keyphrase[\"kw\"]),\n",
    "                        'date':str(keyphrase[\"date\"])\n",
    "                    }\n",
    "    print(\"Headline: \",keyphrase[\"kw\"])\n",
    "    print(\"Data: \",keyphrase[\"date\"])\n",
    "    result_headline[\"persons\"] = []\n",
    "    doc = nlp(keyphrase[\"kw\"])\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PER\": #condição apenas para nomes de pessoas\n",
    "            #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "            datetime_object = datetime.strptime(str(keyphrase[\"date\"]), '%Y-%m-%d %H:%M:%S') #formatar a data para o formato pretendido\n",
    "            datetime_objectMoreOne = datetime_object + relativedelta(years=+1) # adicionar um ano à data para pesquisa na api de imagens\n",
    "            api_url_base = 'https://preprod.arquivo.pt/imagesearch/?' #url da API ArquivoPt\n",
    "            query1 = ent.text #nome para query\n",
    "            maxItems = 1 #maximo de resultados\n",
    "            prettyPrint = 'true' #formatação bonita de resultados\n",
    "            frm = datetime_object.strftime(\"%Y%m%d%H%M%S\") #data formatada\n",
    "            to = datetime_objectMoreOne.strftime(\"%Y%m%d%H%M%S\")#data formatada +1 ano\n",
    "            size = 'md' #tamanho das imagens \n",
    "            type = 'png jpg jpeg'\n",
    "            api_url = '{0}q={1}&maxItems={2}&prettyPrint={3}&to={4}&from={5}&size={6}&type={7}'.format(api_url_base,query1,maxItems,prettyPrint,to,frm,size,type)\n",
    "            response = requests.get(api_url) #resposta api de imagens\n",
    "            imgApiResponse = response.json() #resposta em json api de imagens\n",
    "            if(len(imgApiResponse[\"responseItems\"]) > 0):\n",
    "                result_chunk =   {   'person':str(ent.text), \n",
    "                                    'start_char':str(ent.start_char),\n",
    "                                    'end_char':str(ent.end_char),\n",
    "                                    'date':str(keyphrase[\"date\"]),\n",
    "                                    'imgSrc':str(imgApiResponse[\"responseItems\"][0][\"imgLinkToArchive\"])\n",
    "                                }\n",
    "                print(\"Nome: \",ent.text)\n",
    "                print(\"Start Char: \",ent.start_char)\n",
    "                print(\"End Char: \",ent.end_char)\n",
    "                print(\"Data: \",keyphrase[\"date\"])\n",
    "                print(\"Link imagem: \",imgApiResponse[\"responseItems\"][0][\"imgLinkToArchive\"])\n",
    "            else:\n",
    "                result_chunk =   {   'person':str(ent.text), \n",
    "                                    'start_char':str(ent.start_char),\n",
    "                                    'end_char':str(ent.end_char),\n",
    "                                    'date':str(keyphrase[\"date\"])\n",
    "                                }\n",
    "                print(\"Nome: \",ent.text)\n",
    "                print(\"Start Char: \",ent.start_char)\n",
    "                print(\"End Char: \",ent.end_char)\n",
    "                print(\"Data: \",keyphrase[\"date\"])\n",
    "            result_headline[\"persons\"].append(result_chunk)\n",
    "            print()\n",
    "    result_interval[\"headline\"].append(result_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em baixo esta tudo o que foi apresentado mas em forma de uma API propria para ser apresentado numa pagina de forma visual e com open cv a verificar se existem pessoas na foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "\t# download the image, convert it to a NumPy array, and then read\n",
    "\t# it into OpenCV format\n",
    "\ttry:\n",
    "\t\twith urllib.request.urlopen(url) as response:\n",
    "\t\t\timage = np.asarray(bytearray(response.read()), dtype=\"uint8\")\n",
    "\t\t\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\t \n",
    "\t\t# return the image\n",
    "\t\treturn image\n",
    "\texcept urllib.error.HTTPError as err:\n",
    "\t\tif err.code == 404:\n",
    "\t\t\treturn None\n",
    "\t\telse:\n",
    "\t\t\treturn image\n",
    "\n",
    "class Search(Resource):\n",
    "\tdef get(self, query):\n",
    "\t\t#query = 'Cristiano Ronaldo'\n",
    "\t\tfileName = 'results_opencv/{0}.txt'.format(query)\n",
    "\t\tfileNameFormated = 'results_opencv/{0}-formated.txt'.format(query)\n",
    "\t\tabs_fileName = 'results_opencv/{0}.txt'.format(query)\n",
    "\t\tabs_fileNameFormated = 'results_opencv/{0}-formated.txt'.format(query)\n",
    "\t\tfaceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\t\t#print(fileName)\n",
    "\t\tif not(os.path.isfile(abs_fileName)):\n",
    "\t\t\tapt =  ArquivoPT()\n",
    "\t\t\tsearch_result = apt.getResult(query=query, **params)\n",
    "\n",
    "\t\t\tlanguage = \"pt\"\n",
    "\t\t\t\n",
    "\t\t\tcont = engine.TemporalSummarizationEngine()\n",
    "\t\t\tintervals = cont.build_intervals(search_result, language)\n",
    "\n",
    "\t\t\tf = open(abs_fileName, \"w\")\n",
    "\t\t\tf.write(json.dumps(cont.serialize(intervals)))\n",
    "\t\t\t#cont.pprint(intervals)\n",
    "\t\t\tf.close()\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Já existe\")\n",
    "\n",
    "\t\tif not(os.path.isfile(abs_fileNameFormated)):\n",
    "\t\t\tf = open(abs_fileName, \"r\") \n",
    "\t\t\tsumm_result = json.loads(str(f.read()))\n",
    "\t\t\tnlp = spacy.load('pt_core_news_sm')\n",
    "\t\t\tnewObject = []\n",
    "\n",
    "\t\t\tfor period in summ_result[\"results\"]:\n",
    "\n",
    "\t\t\t\t#print(\"--------------------------------\")\n",
    "\t\t\t\t#print(period[\"from\"],\"until\",period[\"to\"])\n",
    "\t\t\t\tresult_interval =   {   'from':str(period['from']), \n",
    "\t\t\t\t\t\t\t\t\t\t'to':str(period['to'])\n",
    "\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t# selected keyphrases\n",
    "\t\t\t\tkeyphrases = period[\"keyphrases\"]\n",
    "\t\t\t\tresult_interval[\"headline\"] = []\n",
    "\t\t\t\tfor keyphrase in keyphrases:  \n",
    "\t\t\t\t\t#print(keyphrase[\"kw\"])\n",
    "\t\t\t\t\tresult_headline = {\n",
    "\t\t\t\t\t\t'headline':str(keyphrase[\"kw\"]),\n",
    "\t\t\t\t\t\t'date':str(keyphrase[\"date\"])\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\tresult_headline[\"persons\"] = []\n",
    "\t\t\t\t\tdoc = nlp(keyphrase[\"kw\"])\n",
    "\t\t\t\t\tfor ent in doc.ents:\n",
    "\t\t\t\t\t\t\tif ent.label_ == \"PER\":\n",
    "\t\t\t\t\t\t\t\t#print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\t\t\t\t\t\t\t\tdatetime_object = datetime.strptime(str(keyphrase[\"date\"]), '%Y-%m-%d %H:%M:%S')\n",
    "\t\t\t\t\t\t\t\tdatetime_objectMoreOne = datetime_object + relativedelta(years=+1)\n",
    "\t\t\t\t\t\t\t\tapi_url_base = 'https://arquivo.pt/imagesearch/?'\n",
    "\t\t\t\t\t\t\t\tquery1 = ent.text\n",
    "\t\t\t\t\t\t\t\tmaxItems = 10\n",
    "\t\t\t\t\t\t\t\tprettyPrint = 'true'\n",
    "\t\t\t\t\t\t\t\tfrm = datetime_object.strftime(\"%Y%m%d%H%M%S\")\n",
    "\t\t\t\t\t\t\t\tto = datetime_objectMoreOne.strftime(\"%Y%m%d%H%M%S\")\n",
    "\t\t\t\t\t\t\t\tsize = 'md'\n",
    "\t\t\t\t\t\t\t\ttype = 'png jpg jpeg'\n",
    "\t\t\t\t\t\t\t\tapi_url = '{0}q={1}&maxItems={2}&prettyPrint={3}&to={4}&from={5}&size={6}&type={7}'.format(api_url_base,query1,maxItems,prettyPrint,to,frm,size,type)\n",
    "\t\t\t\t\t\t\t\t#print(api_url)\n",
    "\t\t\t\t\t\t\t\tresponse = requests.get(api_url)\n",
    "\t\t\t\t\t\t\t\timgApiResponse = response.json()\n",
    "\t\t\t\t\t\t\t\t#print(imgApiResponse)\n",
    "\t\t\t\t\t\t\t\tif(len(imgApiResponse[\"responseItems\"]) > 0):\n",
    "\t\t\t\t\t\t\t\t\tfor x in range(0, len(imgApiResponse[\"responseItems\"])):\n",
    "\t\t\t\t\t\t\t\t\t\t#print(imgApiResponse[\"responseItems\"][x][\"imgLinkToArchive\"])\n",
    "\t\t\t\t\t\t\t\t\t\timage = url_to_image(imgApiResponse[\"responseItems\"][x][\"imgLinkToArchive\"])\n",
    "\t\t\t\t\t\t\t\t\t\tif image is not None:\n",
    "\t\t\t\t\t\t\t\t\t\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t\t\t\t\t\t\t\t\tfaces = faceCascade.detectMultiScale(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tgray,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tscaleFactor=1.2,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tminNeighbors=5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tminSize=(30, 30),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tflags = cv2.CASCADE_SCALE_IMAGE\n",
    "\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\t\t\t\t\t\t#print(len(faces))\n",
    "\t\t\t\t\t\t\t\t\t\t\tif(len(faces) >= 1): \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t#print(\"encontrou uma cara\")\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tresult_chunk =   {   'person':str(ent.text), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'start_char':str(ent.start_char),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'end_char':str(ent.end_char),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'date':str(keyphrase[\"date\"]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'imgSrc':str(imgApiResponse[\"responseItems\"][x][\"imgLinkToArchive\"]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'faces':str(len(faces))\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tresult_chunk =   {   'person':str(ent.text), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'start_char':str(ent.start_char),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'end_char':str(ent.end_char),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'date':str(keyphrase[\"date\"]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'imgSrc':str('https://upload.wikimedia.org/wikipedia/commons/a/ac/No_image_available.svg')\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tresult_chunk =   {   'person':str(ent.text), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'start_char':str(ent.start_char),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'end_char':str(ent.end_char),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'date':str(keyphrase[\"date\"]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'imgSrc':str('https://upload.wikimedia.org/wikipedia/commons/a/ac/No_image_available.svg')\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\tresult_headline[\"persons\"].append(result_chunk)\n",
    "\t\t\t\t\tresult_interval[\"headline\"].append(result_headline)\n",
    "\t\t\t\tnewObject.append(result_interval)\n",
    "\t\t\t#print(json.dumps(newObject[0]))\n",
    "\t\t\tf.close()\n",
    "\n",
    "\t\t\tf = open(fileNameFormated, \"w\")\n",
    "\t\t\tf.write(json.dumps(newObject))\n",
    "\t\t\treturn fileNameFormated, 200\n",
    "\t\t\t\t# sources\n",
    "\t\t\t\t# for headline in keyphrase[\"headlines\"]:\n",
    "\t\t\t\t#    print(\"Date\", headline[\"info\"][\"datetime\"])\n",
    "\t\t\t\t#    print(\"Source\", headline[\"info\"][\"domain\"])\n",
    "\t\t\t\t#    print(\"Url\", headline[\"info\"][\"url\"])\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t#  print()  \n",
    "\t\telse:\n",
    "\t\t\treturn fileNameFormated, 200\n",
    "\n",
    "@app.route(\"/\")\n",
    "def root():\n",
    "\treturn render_template(\"index.html\")\n",
    "\n",
    "@app.route('/results_opencv/<path:path>')\n",
    "def send_js(path):\n",
    "\treturn send_from_directory('results_opencv', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [07/Apr/2019 01:03:17] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Já existe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Apr/2019 01:03:19] \"GET /query/cristiano%20ronaldo HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2019 01:03:19] \"GET /results_opencv/cristiano%20ronaldo-formated.txt HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "api.add_resource(Search, \"/query/<string:query>\")\n",
    "\n",
    "app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
